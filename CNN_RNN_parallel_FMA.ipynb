{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3563,
     "status": "ok",
     "timestamp": 1562236250749,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "jAyFqlof9NE-",
    "outputId": "f5787d1c-5bf3-4d3f-a83d-8d8c2013cc9e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Bidirectional, LSTM, Dropout, Activation, GRU, BatchNormalization\n",
    "from keras.layers import Conv2D, concatenate, MaxPooling2D, Flatten, Embedding, Lambda\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3539,
     "status": "ok",
     "timestamp": 1562236250749,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "CnVpKxBW9tJr",
    "outputId": "702c5687-4854-49c6-f542-6eaf2ff8cb04"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3522,
     "status": "ok",
     "timestamp": 1562236250750,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "_rH2qLiW9jzQ",
    "outputId": "35643856-5190-4367-f327-aa10133e52f5"
   },
   "outputs": [],
   "source": [
    "cd drive/\"My Drive\"/FMA_Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5041,
     "status": "ok",
     "timestamp": 1562236252291,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "r2guF_77hG_F",
    "outputId": "fb750b3e-80bc-4836-cfe2-b0e2d74266ef"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4CgcUn489NFF"
   },
   "source": [
    "### Load training and Validation arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5026,
     "status": "ok",
     "timestamp": 1562236252291,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "ic51BPDk9NFG",
    "outputId": "e7f42d14-e96b-4e34-a821-95528e61c7ce"
   },
   "outputs": [],
   "source": [
    "dict_genres = {'Electronic':0,  'Folk':1,  'Pop' :2, 'Instrumental':3 }\n",
    "\n",
    "reverse_map = {v: k for k, v in dict_genres.items()}\n",
    "print(reverse_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29626,
     "status": "ok",
     "timestamp": 1562236276899,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "avVhjozs9NFK",
    "outputId": "f46843eb-0399-4ccf-f2f1-8b8bf6511231"
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('loaddata/suf_train_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_train = npzfile['arr_0']\n",
    "y_train = npzfile['arr_1']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32892,
     "status": "ok",
     "timestamp": 1562236280181,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "cFIqi3hm9NFO",
    "outputId": "d8b47cbb-1195-4278-ee8e-872643b0550b"
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('loaddata/suf_valid_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_valid = npzfile['arr_0']\n",
    "y_valid = npzfile['arr_1']\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXy2O0oU-z_C"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_valid = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7vhVHmv9NFX"
   },
   "source": [
    "### Parallel CNN - RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYJT4oAT9NFY"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 4\n",
    "n_features = X_train.shape[2]\n",
    "n_time = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmApV0KS9NFa"
   },
   "outputs": [],
   "source": [
    "nb_filters1=16 \n",
    "nb_filters2=32 \n",
    "nb_filters3=64\n",
    "nb_filters4=64\n",
    "nb_filters5=64\n",
    "ksize = (3,3)\n",
    "pool_size_1= (2,2) \n",
    "pool_size_2 = (4,2)\n",
    "\n",
    "lstm_count = 64\n",
    "num_units = 120\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 70\n",
    "L2_regularization = 0.001\n",
    "\n",
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "    \n",
    "        ### Convolutional blocks\n",
    "    conv_1 = Conv2D(filters = nb_filters1, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_1')(layer)\n",
    "    batch_1 = BatchNormalization()(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size_1)(batch_1)\n",
    "    dropout_1=Dropout(0.25)(pool_1)\n",
    "\n",
    "    conv_2 = Conv2D(filters = nb_filters2, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_2')(dropout_1)\n",
    "    batch_2 = BatchNormalization()(conv_2)\n",
    "    pool_2 = MaxPooling2D(pool_size_1)(conv_2)\n",
    "    dropout_2=Dropout(0.25)(pool_2)\n",
    "\n",
    "    conv_3 = Conv2D(filters = nb_filters3, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_3')(dropout_2)\n",
    "    batch_3 = BatchNormalization()(conv_3)\n",
    "    pool_3 = MaxPooling2D(pool_size_1)(conv_3)\n",
    "    dropout_3=Dropout(0.25)(pool_3)\n",
    "    \n",
    "    conv_4 = Conv2D(filters = nb_filters4, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_4')(dropout_3)\n",
    "    batch_4 = BatchNormalization()(conv_4)\n",
    "    pool_4 = MaxPooling2D(pool_size_1)(conv_4)\n",
    "    dropout_4=Dropout(0.25)(pool_4)\n",
    "    \n",
    "    conv_5 = Conv2D(filters = nb_filters5, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_5')(dropout_4)\n",
    "    batch_5 = BatchNormalization()(conv_5)\n",
    "    pool_5 = MaxPooling2D(pool_size_1)(conv_5)\n",
    "    dropout_5=Dropout(0.25)(pool_5)\n",
    "    flatten1 = Flatten()(dropout_5)\n",
    "    ### Recurrent Block\n",
    "    \n",
    "    # Pooling layer\n",
    "    pool_lstm1 = MaxPooling2D(pool_size_2, name = 'pool_lstm')(layer)\n",
    "    \n",
    "    # Embedding layer\n",
    "\n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, axis= -1))(pool_lstm1)\n",
    "    \n",
    "    # Bidirectional GRU\n",
    "    lstm = Bidirectional(GRU(lstm_count))(squeezed)  #default merge mode is concat\n",
    "    \n",
    "    # Concat Output\n",
    "    concat = concatenate([flatten1, lstm], axis=-1, name ='concat')\n",
    "    dropout_6=Dropout(0.25)(concat)\n",
    "    ## Softmax Output\n",
    "    output = Dense(num_classes, activation = 'softmax', name='preds')(dropout_6)\n",
    "    \n",
    "    model_output = output\n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    #opt = RMSprop(lr=0.0005)  # Optimizer\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4chuawyR9NFd"
   },
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val):\n",
    "    \n",
    "    n_frequency = 128\n",
    "    n_frames = 420\n",
    "    #reshape and expand dims for conv2d\n",
    "#     x_train = x_train.reshape(-1, n_frequency, n_frames)\n",
    "    x_train = np.expand_dims(x_train, axis = -1)\n",
    "    \n",
    "#     x_val = x_val.reshape(-1, n_frequency, n_frames)\n",
    "    x_val = np.expand_dims(x_val, axis = -1)\n",
    "    \n",
    "    \n",
    "    input_shape = (n_frames, n_frequency, 1)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    \n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "    \n",
    "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "#                               embeddings_metadata=None)\n",
    "    checkpoint_callback = ModelCheckpoint('./models/parallel/weights.best.h5', monitor='val_acc', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "  \n",
    "    #earlyStopping = EarlyStopping(monitor='val_acc', patience=70, verbose=1, mode='max')\n",
    "    \n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(x_val, y_val), verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDLnqr_X9NFg"
   },
   "outputs": [],
   "source": [
    "def show_summary_stats(history):\n",
    "    # List all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29067,
     "status": "error",
     "timestamp": 1561700071608,
     "user": {
      "displayName": "chontipan plengvittaya",
      "photoUrl": "",
      "userId": "10515451504317762035"
     },
     "user_tz": -480
    },
    "id": "TkYrcW9l9NFj",
    "outputId": "835ea423-e8ee-4975-8778-b92d9e930ff1"
   },
   "outputs": [],
   "source": [
    "model, history  = train_model(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYqKGDpj9NFm"
   },
   "outputs": [],
   "source": [
    "show_summary_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFfEBbDP9NFq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = np.argmax(y_valid, axis = 1)\n",
    "X_valid = np.expand_dims(X_valid, axis = -1)\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "labels = [0,1,2,3,4]\n",
    "target_names = dict_genres.keys()\n",
    "\n",
    "print(y_true.shape, y_pred.shape)\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFBN8gzl9NFt"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03C3iNfy9NFx"
   },
   "source": [
    "### Look at the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yg2zfZKn9NFy"
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('loaddata/test_arr.npz')\n",
    "print(npzfile.files)\n",
    "X_test = npzfile['arr_0']\n",
    "y_test = npzfile['arr_1']\n",
    "print(X_test.shape, y_test.shape)\n",
    "te_idx = np.random.permutation(len(X_test))\n",
    "X_test = X_test[te_idx]\n",
    "y_test = y_test[te_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtNN6Kkf9NF3"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "weights_path = 'models/parallel/weights.best.h5'\n",
    "model = load_model(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAeVoETf9NF6"
   },
   "outputs": [],
   "source": [
    "print(np.amin(y_test), np.amax(y_test), np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqKyE9699NGD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = y_test\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "labels = [0,1,2,3]\n",
    "target_names = dict_genres.keys()\n",
    "\n",
    "print(y_true.shape, y_pred.shape)\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dC7Vuks89NGH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=dict_genres.keys(),\n",
    "            yticklabels=dict_genres.keys())\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIdpqx6T9NGK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_RNN_parallel_FMA.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
